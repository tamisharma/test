{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection lesson/lab\n",
    "\n",
    "In this codealong we will explore different ways of performing **feature selection**.\n",
    "\n",
    "Feature selection is the process of reducing the number of predictors in your data based on their calculated \"usefulness\". This is the flip side of the process of **feature engineering**, where you create new descriptive predictors from the data you already have.\n",
    "\n",
    "You have already had experience with the **Lasso**, which (in my opinion), is the best feature selector despite it's downsides. [ASIDE: The downsides of the Lasso are in fact addressed by the \"Elastic Net\" penalty, which combines the Ridge regularization with the Lasso regularization!]\n",
    "\n",
    "In the first half we will be revisiting and practicing using the Lasso in a classification task of identifying spam text messages from the appearance of particular words in the text message. This dataset has been created with the `CountVectorizer` that you are familiar with from previous lessons, though you will not be using it here in the interest of time.\n",
    "\n",
    "The second half you will explore, as groups, alternative methods of doing feature selection provided in the scikit-learn package and then presenting on how they work.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam = pd.read_csv('../../assets/datasets/spam_words_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_spam</th>\n",
       "      <th>getzed</th>\n",
       "      <th>86021</th>\n",
       "      <th>babies</th>\n",
       "      <th>sunoco</th>\n",
       "      <th>ultimately</th>\n",
       "      <th>thk</th>\n",
       "      <th>voted</th>\n",
       "      <th>spatula</th>\n",
       "      <th>fiend</th>\n",
       "      <th>...</th>\n",
       "      <th>itna</th>\n",
       "      <th>borin</th>\n",
       "      <th>thoughts</th>\n",
       "      <th>iccha</th>\n",
       "      <th>videochat</th>\n",
       "      <th>freefone</th>\n",
       "      <th>pist</th>\n",
       "      <th>reformat</th>\n",
       "      <th>strict</th>\n",
       "      <th>69698</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_spam  getzed  86021  babies  sunoco  ultimately  thk  voted  spatula  \\\n",
       "0        0       0      0       0       0           0    0      0        0   \n",
       "1        0       0      0       0       0           0    0      0        0   \n",
       "2        1       0      0       0       0           0    0      0        0   \n",
       "3        0       0      0       0       0           0    0      0        0   \n",
       "4        0       0      0       0       0           0    0      0        0   \n",
       "\n",
       "   fiend  ...    itna  borin  thoughts  iccha  videochat  freefone  pist  \\\n",
       "0      0  ...       0      0         0      0          0         0     0   \n",
       "1      0  ...       0      0         0      0          0         0     0   \n",
       "2      0  ...       0      0         0      0          0         0     0   \n",
       "3      0  ...       0      0         0      0          0         0     0   \n",
       "4      0  ...       0      0         0      0          0         0     0   \n",
       "\n",
       "   reformat  strict  69698  \n",
       "0         0       0      0  \n",
       "1         0       0      0  \n",
       "2         0       0      0  \n",
       "3         0       0      0  \n",
       "4         0       0      0  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 1001)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Find baseline rate of spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13406317300789664"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(len(spam[spam['is_spam'] == 1])) / len(spam)\n",
    "\n",
    "# can also express it this way since it's a binary dataset\n",
    "\n",
    "spam.is_spam.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going below 10%, and especially below 5% classification becomes very tricky due to a small sample\n",
    "\n",
    "Have to be very careful to find the differencese between the two with very small "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1 Cross-validate logistic regression accuracy\n",
    "\n",
    "Use these classes/methods from scikit-learn:\n",
    "\n",
    "    LogisticRegression\n",
    "    cross_val_score\n",
    "    \n",
    "Cross-validate the logistic regression with 5 folds.\n",
    "\n",
    "Also save the X matrix column headers for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "\n",
    "Y = 'is_spam'\n",
    "X = [col for col in spam.columns if col != Y]\n",
    "\n",
    "target = spam[Y]\n",
    "X = spam[X]\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(model, X, target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.92735426  0.93363229  0.93177738  0.93806104  0.94344704]\n",
      "0.934854400979\n"
     ]
    }
   ],
   "source": [
    "print scores\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing threshold\n",
    "model.fit(X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.97997764  0.02002236]\n",
      " [ 0.93243347  0.06756653]\n",
      " [ 0.93243347  0.06756653]\n",
      " [ 0.97674543  0.02325457]\n",
      " [ 0.93243347  0.06756653]]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "pp = model.predict_proba(X)\n",
    "print pp[0:5]\n",
    "y_pred_50pct = model.predict(X)\n",
    "print model.classes_\n",
    "# OUr model is convery confident that thse points are 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4813</td>\n",
       "      <td>12</td>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "      <td>464</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>5096</td>\n",
       "      <td>476</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0    1   All\n",
       "True                      \n",
       "0          4813   12  4825\n",
       "1           283  464   747\n",
       "All        5096  476  5572"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# confusion_matrix(y, y_pred_50pct)\n",
    "Ytrue = pd.Series(Y)\n",
    "Ypred50 = pd.Series(y_pred_50pct)\n",
    "pd.crosstab(target, Ypred50, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1584</td>\n",
       "      <td>3241</td>\n",
       "      <td>4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>742</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1589</td>\n",
       "      <td>3983</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "True                       \n",
       "0          1584  3241  4825\n",
       "1             5   742   747\n",
       "All        1589  3983  5572"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_95pct = [0 if row[0] > 0.95 else 1 for row in pp]\n",
    "ypred95 = pd.Series(y_pred_95pct)\n",
    "pd.crosstab(target, ypred95, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want accuracy chose 50%, \n",
    "\n",
    "If want to minimize false negatives increase the threshold to be super confident. You're sacraficing a lot of true values but are very confident in your True Positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2 Cross-validate logistic regression area under ROC\n",
    "\n",
    "The `scoring` keyword argument in `cross_val_score()` can take different scoring metrics than the default \"accuracy\".\n",
    "\n",
    "For more information on how to use this [read the documentation on model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html) particularly in **Section 3.3.1**.\n",
    "\n",
    "Why is using the area under the ROC curve more informative than the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3 Cross-validate the logistic regression, scoring on the area under the precision-recall curve\n",
    "\n",
    "The \"average_precision\" is the area under the precision-recall curve, whereas \"precision\" is simply the precision without taking recall into consideration.\n",
    "\n",
    "Why/when might you decide to use precision and recall in a classification task (area under precision-recal curve) versus specificity and sensitivity (area under the ROC curve)?\n",
    "\n",
    "These wikipedia pages are good references for refreshing your memory or figuring out the differences and goals of each:\n",
    "\n",
    "1. [Confusion matrices](https://en.wikipedia.org/wiki/Confusion_matrix)\n",
    "2. [ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)\n",
    "3. [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall)\n",
    "4. [Type I and Type II errors](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3 Fit the logistic regression on all the data and calculate the number of non-negative coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.1 Cross-validate logreg Lasso regularization using the 'average_precision' scoring metric\n",
    "\n",
    "Use the sklearn class:\n",
    "\n",
    "    LogisticRegressionCV\n",
    "    \n",
    "Remember that these keyword arguments need to be used for the Lasso:\n",
    "\n",
    "    solver='liblinear'\n",
    "    penalty='l1' (That is a lowercase 'L' first!)\n",
    "    \n",
    "Cross-validate with 25 folds and print out the best regularization parameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.2 Build a logistic regression using Lasso penalty with the optimal C and cross-validate area under the precision-recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.3 Find how many non-zero coefficients there are for this model\n",
    "\n",
    "How does this compare to the non-Lasso model? Explain why the Lasso performs \"feature selection\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.4 Repeat this process but with scoring='precision'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_lasso_cv = LogisticRegressionCV(solver='liblinear', cv=5, penalty='l1', Cs=25,\n",
    "                                   scoring='precision')\n",
    "\n",
    "lr_lasso_cv.fit(X, Y)\n",
    "\n",
    "print lr_lasso_cv.C_\n",
    "\n",
    "lr_lasso = LogisticRegression(solver='liblinear', penalty='l1', C=lr_lasso_cv.C_[0])\n",
    "\n",
    "scores = cross_val_score(lr_lasso, X, Y, cv=5, scoring='precision')\n",
    "print np.mean(scores)\n",
    "\n",
    "lr_lasso.fit(X, Y)\n",
    "\n",
    "print np.sum(lr_lasso.coef_[0] != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.5 Use the X column names and the coefficients from the logistic regression to find out which features were kept when scoring for precision with the Lasso penalty\n",
    "\n",
    "Explain what these chosen features are useful for when scoring for optimal precision.\n",
    "\n",
    "Why are there so few compared to the area under the precision-recall curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Explore other feature selection methods\n",
    "\n",
    "scikit-learn comes with [a variety of other feature selection methods](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection).\n",
    "\n",
    "For the next section you will explore as groups these methods:\n",
    "\n",
    "**Group 1**\n",
    "    \n",
    "    feature_selection.SelectPercentile\n",
    "    feature_selection.SelectKBest\n",
    "    \n",
    "**Group 2**\n",
    "    \n",
    "    feature_selection.RFE\n",
    "    feature_selection.RFECV\n",
    "    \n",
    "**Group 3**\n",
    "    \n",
    "    feature_selection.SelectFpr\n",
    "    feature_selection.SelectFdr\n",
    "    \n",
    "**Group 4**\n",
    "\n",
    "    feature_selection.VarianceThreshold\n",
    "    feature_selection.SelectFwe\n",
    "    \n",
    "---\n",
    "\n",
    "#### Questions for presentation\n",
    "\n",
    "After exploring the assigned feature selection methods, you will, as a group, present to the class on:\n",
    "\n",
    "1. How the feature selection method is designed to reduce the number of predictors.\n",
    "2. What scenario(s) you think the method would be particularly useful in.\n",
    "3. How to implement the method in code.\n",
    "4. [BONUS] Possible downsides to using the feature selection method (if any).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
