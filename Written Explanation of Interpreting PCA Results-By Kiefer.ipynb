{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../capstone-projects/speed-dating-experiment/Speed Dating Data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import seabord and matplotlib modules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#makes visualizations appear inline with code in notebook\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub = df[[\"gender\",\"imprelig\", \"goal\", \"date\",\"go_out\", 'exphappy', 'expnum','attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1',\"match\",\"samerace\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ltdanp21/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "match_diff_rc_mask = (sub[\"match\"] == 1) & (sub[\"samerace\"] == 0)\n",
    "\n",
    "sub[\"match_diff_race\"] = \"NaN\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ltdanp21/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:461: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "#create \"new target\" column based on values of two columns:\n",
    "\n",
    "# create a mask that meets your condition\n",
    "mask = ((sub[\"match\"] == 1) & (sub[\"samerace\"] == 0))\n",
    "\n",
    "#call DF.iloc[passmask,\"new_column_name] = what you want column equal to \n",
    "sub.loc[mask, 'match_diff_race'] = 1\n",
    "#call DF.iloc[~passmask,\"new_column_name] = what you want column equal to\n",
    "#tilde to say not equal to condition, so that you can have the \"opposite\" classification\n",
    "sub.loc[~mask, 'match_diff_race'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_list = list(df.columns)\n",
    "#print columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ltdanp21/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "sub.drop(['match',\"samerace\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>imprelig</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>go_out</th>\n",
       "      <th>exphappy</th>\n",
       "      <th>expnum</th>\n",
       "      <th>attr1_1</th>\n",
       "      <th>sinc1_1</th>\n",
       "      <th>intel1_1</th>\n",
       "      <th>fun1_1</th>\n",
       "      <th>amb1_1</th>\n",
       "      <th>shar1_1</th>\n",
       "      <th>match_diff_race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  imprelig  goal  date  go_out  exphappy  expnum  attr1_1  sinc1_1  \\\n",
       "0       0       4.0   2.0   7.0     1.0       3.0     2.0     15.0     20.0   \n",
       "1       0       4.0   2.0   7.0     1.0       3.0     2.0     15.0     20.0   \n",
       "2       0       4.0   2.0   7.0     1.0       3.0     2.0     15.0     20.0   \n",
       "3       0       4.0   2.0   7.0     1.0       3.0     2.0     15.0     20.0   \n",
       "4       0       4.0   2.0   7.0     1.0       3.0     2.0     15.0     20.0   \n",
       "\n",
       "   intel1_1  fun1_1  amb1_1  shar1_1 match_diff_race  \n",
       "0      20.0    15.0    15.0     15.0               0  \n",
       "1      20.0    15.0    15.0     15.0               0  \n",
       "2      20.0    15.0    15.0     15.0               0  \n",
       "3      20.0    15.0    15.0     15.0               1  \n",
       "4      20.0    15.0    15.0     15.0               1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()\n",
    "# 1 = will date outside race\n",
    "# 0 = will not date outside race\n",
    "# risk = race may not have been an issue, simply did not vibe with the person?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7564\n",
       "1     814\n",
       "Name: match_diff_race, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[\"match_diff_race\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'gender', u'imprelig', u'goal', u'date', u'go_out', u'exphappy',\n",
       "       u'expnum', u'attr1_1', u'sinc1_1', u'intel1_1', u'fun1_1', u'amb1_1',\n",
       "       u'shar1_1', u'match_diff_race'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                0\n",
       "imprelig             79\n",
       "goal                 79\n",
       "date                 97\n",
       "go_out               79\n",
       "exphappy            101\n",
       "expnum             6578\n",
       "attr1_1              79\n",
       "sinc1_1              79\n",
       "intel1_1             79\n",
       "fun1_1               89\n",
       "amb1_1               99\n",
       "shar1_1             121\n",
       "match_diff_race       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gender                0\n",
    "\n",
    "imprelig             79\n",
    "\n",
    "goal                 79\n",
    "\n",
    "date                 97\n",
    "\n",
    "go_out               79\n",
    "\n",
    "exphappy            101\n",
    "\n",
    "expnum             6578\n",
    "\n",
    "attr1_1              79\n",
    "\n",
    "sinc1_1              79\n",
    "\n",
    "intel1_1             79\n",
    "\n",
    "fun1_1               89\n",
    "\n",
    "amb1_1               99\n",
    "\n",
    "shar1_1             121\n",
    "\n",
    "match_diff_race       0\n",
    "\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ltdanp21/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "sub.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender             0\n",
       "imprelig           0\n",
       "goal               0\n",
       "date               0\n",
       "go_out             0\n",
       "exphappy           0\n",
       "expnum             0\n",
       "attr1_1            0\n",
       "sinc1_1            0\n",
       "intel1_1           0\n",
       "fun1_1             0\n",
       "amb1_1             0\n",
       "shar1_1            0\n",
       "match_diff_race    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, conduct a PCA using scikit learn\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define the x and y variables: Airport is going to be our \"x\" variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, standardize the x variable for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b17029ecde90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#convert normalized columns back to a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m x_norm = pd.DataFrame(x_std, columns = ['gender', 'imprelig', 'goal', 'date', 'go_out', 'exphappy',\n\u001b[0m\u001b[1;32m      3\u001b[0m        \u001b[0;34m'expnum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attr1_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sinc1_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'intel1_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fun1_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'amb1_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        'shar1_1'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_std' is not defined"
     ]
    }
   ],
   "source": [
    "#convert normalized columns back to a dataframe\n",
    "x_norm = pd.DataFrame(x_std, columns = ['gender', 'imprelig', 'goal', 'date', 'go_out', 'exphappy',\n",
    "       'expnum', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "       'shar1_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert response column to dataframe\n",
    "y_df = pd.DataFrame(y, columns = [\"match_diff_race\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create the covariance matrix from the standardized x-values and decompose these values to find the eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(x_norm.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_norm.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What will this function return and in what order? \n",
    "#Will return eigenValues first and eigenvectors second \n",
    "#pass df.corr to np.linalg.eig() \n",
    "eigenValues, eigenVectors = np.linalg.eig(x_norm.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, check your eigenvalues and eigenvectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the principal componants, find the eigenpairs, and sort them from highest to lowest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_eigenVectors = np.sort(eigenVectors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_eigenValues = np.sort(eigenValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Calculate the explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# figure this out...\n",
    "eigen_total = sum(eigenValues)\n",
    "\n",
    "def eigen_score(x):\n",
    "   ExplainedVariance = (eigenValues[x]/eigen_total) * 100\n",
    "   return \"Explained Variance\", x+1, ExplainedVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, conduct the PCA - use the results about to guide your selection of \"n\" componants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x2 = sub[['gender', 'imprelig', 'goal', 'date', 'go_out', 'exphappy',\n",
    "       'expnum', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "       'shar1_1']]\n",
    "\n",
    "y2 = sub[[\"match_diff_race\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#normalize predictor columns-instantiate function\n",
    "ss = StandardScaler()\n",
    "\n",
    "#pass predictor columns through normalizer\n",
    "x_std2 = ss.fit_transform(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca2 = PCA()\n",
    "\n",
    "test_pca = pca2.fit_transform(x_std2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20102096,  0.13545705,  0.11169525,  0.08996495,  0.08787558,\n",
       "        0.07525819,  0.06792594,  0.06085155,  0.05294239,  0.04871263,\n",
       "        0.03607487,  0.02980453,  0.00241612])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = pca2.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6132724530805427, 1.7609416692072219, 1.4520382592970791, 1.1695443032608455, 1.1423825418615861, 0.97835640879219943, 0.88303719648711376, 0.79107011709032293, 0.68825107698733545, 0.63326415938444025, 0.46897333164480681, 0.3874589379704016, 0.031409544936107793]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# just to check\n",
    "evalue, evector = np.linalg.eig(pd.DataFrame(x_std2).corr().values)\n",
    "a, b, c = np.linalg.svd(pd.DataFrame(x_std2).corr().values)\n",
    "\n",
    "pairs = [[eva, eve] for eva, eve in zip(evalue, evector)]\n",
    "pairs = sorted(pairs, reverse=True)\n",
    "\n",
    "print [p[0] for p in pairs]\n",
    "#print [p[0]/np.sum(evalue) for p in pairs]\n",
    "#print [p[0] for p in pairs]\n",
    "#print pca.explained_variance_\n",
    "\n",
    "sk_comps = pd.DataFrame(pca2.components_)\n",
    "eigvecs = pd.DataFrame(a.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.61327245,  1.76094167,  1.45203826,  1.1695443 ,  1.14238254,\n",
       "        0.97835641,  0.8830372 ,  0.79107012,  0.68825108,  0.63326416,\n",
       "        0.46897333,  0.38745894,  0.03140954])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca2.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.297442</td>\n",
       "      <td>-0.260138</td>\n",
       "      <td>0.016799</td>\n",
       "      <td>-0.349198</td>\n",
       "      <td>-0.221230</td>\n",
       "      <td>0.137536</td>\n",
       "      <td>0.314907</td>\n",
       "      <td>0.516838</td>\n",
       "      <td>-0.277575</td>\n",
       "      <td>-0.092861</td>\n",
       "      <td>0.027921</td>\n",
       "      <td>-0.330043</td>\n",
       "      <td>-0.303496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.337432</td>\n",
       "      <td>0.192843</td>\n",
       "      <td>-0.453440</td>\n",
       "      <td>-0.326096</td>\n",
       "      <td>-0.231418</td>\n",
       "      <td>0.217361</td>\n",
       "      <td>0.397580</td>\n",
       "      <td>-0.144592</td>\n",
       "      <td>-0.201000</td>\n",
       "      <td>-0.147902</td>\n",
       "      <td>0.205687</td>\n",
       "      <td>0.365438</td>\n",
       "      <td>0.138201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.261494</td>\n",
       "      <td>-0.231727</td>\n",
       "      <td>0.097862</td>\n",
       "      <td>0.218699</td>\n",
       "      <td>0.119154</td>\n",
       "      <td>0.402037</td>\n",
       "      <td>0.136330</td>\n",
       "      <td>-0.040748</td>\n",
       "      <td>0.390333</td>\n",
       "      <td>-0.626547</td>\n",
       "      <td>0.215615</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.037171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.395012</td>\n",
       "      <td>-0.213154</td>\n",
       "      <td>0.062549</td>\n",
       "      <td>0.067216</td>\n",
       "      <td>0.315351</td>\n",
       "      <td>-0.440236</td>\n",
       "      <td>0.163871</td>\n",
       "      <td>0.161657</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>-0.154625</td>\n",
       "      <td>0.107514</td>\n",
       "      <td>0.319403</td>\n",
       "      <td>-0.553509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040697</td>\n",
       "      <td>0.102624</td>\n",
       "      <td>-0.057920</td>\n",
       "      <td>-0.134780</td>\n",
       "      <td>0.199287</td>\n",
       "      <td>-0.121683</td>\n",
       "      <td>0.212114</td>\n",
       "      <td>0.269139</td>\n",
       "      <td>0.115847</td>\n",
       "      <td>-0.220657</td>\n",
       "      <td>-0.790317</td>\n",
       "      <td>0.181459</td>\n",
       "      <td>0.273320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.208908</td>\n",
       "      <td>-0.357038</td>\n",
       "      <td>0.162725</td>\n",
       "      <td>-0.238490</td>\n",
       "      <td>-0.409424</td>\n",
       "      <td>0.130884</td>\n",
       "      <td>0.128820</td>\n",
       "      <td>-0.253283</td>\n",
       "      <td>0.537355</td>\n",
       "      <td>0.281462</td>\n",
       "      <td>-0.263638</td>\n",
       "      <td>0.041397</td>\n",
       "      <td>-0.202060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.101194</td>\n",
       "      <td>-0.019924</td>\n",
       "      <td>0.513674</td>\n",
       "      <td>0.030077</td>\n",
       "      <td>-0.573946</td>\n",
       "      <td>-0.338077</td>\n",
       "      <td>-0.104718</td>\n",
       "      <td>0.057909</td>\n",
       "      <td>-0.204672</td>\n",
       "      <td>-0.341967</td>\n",
       "      <td>0.048567</td>\n",
       "      <td>0.173741</td>\n",
       "      <td>0.274208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.044005</td>\n",
       "      <td>-0.636675</td>\n",
       "      <td>-0.584756</td>\n",
       "      <td>0.092765</td>\n",
       "      <td>-0.125110</td>\n",
       "      <td>-0.230619</td>\n",
       "      <td>-0.307078</td>\n",
       "      <td>0.037312</td>\n",
       "      <td>-0.027800</td>\n",
       "      <td>-0.118236</td>\n",
       "      <td>-0.030308</td>\n",
       "      <td>-0.076345</td>\n",
       "      <td>0.236932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.129737</td>\n",
       "      <td>-0.426281</td>\n",
       "      <td>0.259834</td>\n",
       "      <td>0.264352</td>\n",
       "      <td>0.166056</td>\n",
       "      <td>0.418221</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>-0.003736</td>\n",
       "      <td>-0.487772</td>\n",
       "      <td>0.291240</td>\n",
       "      <td>-0.155001</td>\n",
       "      <td>0.279548</td>\n",
       "      <td>0.159363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.286892</td>\n",
       "      <td>0.259756</td>\n",
       "      <td>-0.191778</td>\n",
       "      <td>0.471772</td>\n",
       "      <td>-0.350971</td>\n",
       "      <td>0.340339</td>\n",
       "      <td>-0.254968</td>\n",
       "      <td>0.315778</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>-0.112671</td>\n",
       "      <td>-0.240192</td>\n",
       "      <td>-0.021243</td>\n",
       "      <td>-0.341014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.317094</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>-0.014988</td>\n",
       "      <td>-0.414539</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.131432</td>\n",
       "      <td>-0.580669</td>\n",
       "      <td>0.051036</td>\n",
       "      <td>-0.071943</td>\n",
       "      <td>0.022882</td>\n",
       "      <td>-0.037368</td>\n",
       "      <td>0.555301</td>\n",
       "      <td>-0.233799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.557257</td>\n",
       "      <td>-0.048526</td>\n",
       "      <td>0.200738</td>\n",
       "      <td>-0.411729</td>\n",
       "      <td>0.283864</td>\n",
       "      <td>0.266391</td>\n",
       "      <td>-0.341327</td>\n",
       "      <td>0.110659</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>-0.241080</td>\n",
       "      <td>0.042832</td>\n",
       "      <td>-0.337024</td>\n",
       "      <td>0.151408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.074539</td>\n",
       "      <td>-0.023408</td>\n",
       "      <td>-0.013123</td>\n",
       "      <td>-0.031737</td>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.023184</td>\n",
       "      <td>-0.654420</td>\n",
       "      <td>-0.376450</td>\n",
       "      <td>-0.371539</td>\n",
       "      <td>-0.341370</td>\n",
       "      <td>-0.229479</td>\n",
       "      <td>-0.338976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.297442 -0.260138  0.016799 -0.349198 -0.221230  0.137536  0.314907   \n",
       "1  -0.337432  0.192843 -0.453440 -0.326096 -0.231418  0.217361  0.397580   \n",
       "2   0.261494 -0.231727  0.097862  0.218699  0.119154  0.402037  0.136330   \n",
       "3  -0.395012 -0.213154  0.062549  0.067216  0.315351 -0.440236  0.163871   \n",
       "4   0.040697  0.102624 -0.057920 -0.134780  0.199287 -0.121683  0.212114   \n",
       "5  -0.208908 -0.357038  0.162725 -0.238490 -0.409424  0.130884  0.128820   \n",
       "6  -0.101194 -0.019924  0.513674  0.030077 -0.573946 -0.338077 -0.104718   \n",
       "7  -0.044005 -0.636675 -0.584756  0.092765 -0.125110 -0.230619 -0.307078   \n",
       "8  -0.129737 -0.426281  0.259834  0.264352  0.166056  0.418221  0.106061   \n",
       "9  -0.286892  0.259756 -0.191778  0.471772 -0.350971  0.340339 -0.254968   \n",
       "10  0.317094  0.012511 -0.014988 -0.414539  0.007452  0.131432 -0.580669   \n",
       "11 -0.557257 -0.048526  0.200738 -0.411729  0.283864  0.266391 -0.341327   \n",
       "12  0.074539 -0.023408 -0.013123 -0.031737  0.007669  0.000180 -0.023184   \n",
       "\n",
       "          7         8         9         10        11        12  \n",
       "0   0.516838 -0.277575 -0.092861  0.027921 -0.330043 -0.303496  \n",
       "1  -0.144592 -0.201000 -0.147902  0.205687  0.365438  0.138201  \n",
       "2  -0.040748  0.390333 -0.626547  0.215615  0.177899  0.037171  \n",
       "3   0.161657  0.001108 -0.154625  0.107514  0.319403 -0.553509  \n",
       "4   0.269139  0.115847 -0.220657 -0.790317  0.181459  0.273320  \n",
       "5  -0.253283  0.537355  0.281462 -0.263638  0.041397 -0.202060  \n",
       "6   0.057909 -0.204672 -0.341967  0.048567  0.173741  0.274208  \n",
       "7   0.037312 -0.027800 -0.118236 -0.030308 -0.076345  0.236932  \n",
       "8  -0.003736 -0.487772  0.291240 -0.155001  0.279548  0.159363  \n",
       "9   0.315778  0.002749 -0.112671 -0.240192 -0.021243 -0.341014  \n",
       "10  0.051036 -0.071943  0.022882 -0.037368  0.555301 -0.233799  \n",
       "11  0.110659  0.023159 -0.241080  0.042832 -0.337024  0.151408  \n",
       "12 -0.654420 -0.376450 -0.371539 -0.341370 -0.229479 -0.338976  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_comps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29744168 -0.33743177  0.26149425 -0.39501211  0.04069665 -0.20890833\n",
      " -0.1011943  -0.04400474 -0.12973707 -0.28689216  0.31709398 -0.55725699\n",
      "  0.07453901]\n"
     ]
    }
   ],
   "source": [
    "# The \"components\" in the PCA are essentially the mappings or weightings that will allow us to \n",
    "# transform our original coordinate system into the new principal component coordinate system.\n",
    "#\n",
    "# Every principal component is a linear combination of our original variables. Some variables\n",
    "# from our original data may be more or less important to deriving the NEW coordinate on\n",
    "# a given principal component axis.\n",
    "#\n",
    "# For example, going back to the dating example, PC1 (shallowness) is going to be a combination\n",
    "# of the three questions we asked: values physical attractiveness, likes money, and \n",
    "# enjoys good food. Our \"component\" vector for PC1 is going to convert their answers on the\n",
    "# 3 questions to get a value for shallowness, which is our new axis. Originally perhaps \n",
    "# the \"x-axis\" was \"likes money\". Now the x-axis is shallowness.\n",
    "#\n",
    "# Alright, so to get a person's shallowness value, we will multiply each component by each\n",
    "# variable column. The vector of components for PC1: [c1, c2, c3] are weights for each column\n",
    "# in our data. So:\n",
    "# X_row1 = [attractiveness1, money1, food1]\n",
    "# To get shallowness, we multiply the component vector across columns and add them together:\n",
    "# shallowness1 = (c1 * attractiveness1) + (c2 * money1) + (c3 * food1)\n",
    "#\n",
    "# So in our new PCA matrix, which will have the same number of dimensions as our original,\n",
    "# we can put that value in for the PC1 column:\n",
    "#\n",
    "# PC1             PC2    PC3\n",
    "# [shallowness1, ...., .....]\n",
    "# [    ....    , ...., .....]\n",
    "#\n",
    "# To get the PC2 and PC3, whatever they may represent, for this first person, we will need\n",
    "# to multiply THEIR component vectors across that first row as well and summing them. Once\n",
    "# we have the value we can fill it in for PC2 and PC3.\n",
    "#\n",
    "# Remember: all principal component variables are linear combinations of our original \n",
    "# variables, just in different ways. So shallowness may be \n",
    "# 0.4*money + 0.7*attactiveness + 0.01*food, but PC2 will have different weights for\n",
    "# each of the columns since PC2 MUST BE UNRELATED TO PC1!\n",
    "#\n",
    "# Perhaps PC2 stands for \"love of finding cheap food\", for example. The equation for PC2\n",
    "# might then be:\n",
    "# PC2 = (0.7*money) + (0.01*attractiveness) + (0.5*food)\n",
    "#\n",
    "# Because liking money and liking food mean you like cheap but good food.\n",
    "#\n",
    "# Notice how the shallowness PC1 variable and the cheap food PC2 variable are created from\n",
    "# the same columns in our original dataset, but in different ways. For shallowness the food\n",
    "# column is not very important at all. For cheap food the attractiveness column is not\n",
    "# very important at all. \n",
    "#\n",
    "# Furthermore, being a shallow person and liking cheap food are character traits that are\n",
    "# unrelated to each other. PCA guarantees that the new variables are not related.\n",
    "#\n",
    "# let's get the components out of the sklearn PCA object:\n",
    "components = pca2.components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'gender', u'imprelig', u'goal', u'date', u'go_out', u'exphappy',\n",
      "       u'expnum', u'attr1_1', u'sinc1_1', u'intel1_1', u'fun1_1', u'amb1_1',\n",
      "       u'shar1_1'],\n",
      "      dtype='object')\n",
      "[-1.02043344  0.03553658 -0.16338008  1.34513361 -0.87415579 -1.53383692\n",
      " -0.74963845 -0.66687713  0.43409795 -0.24261819 -0.35912626  0.72236313\n",
      "  0.6216566 ]\n"
     ]
    }
   ],
   "source": [
    "# These are the original coordinates for the first row/observation along your standardized variables.\n",
    "# So, these are the attributes for \"person 1\" on the dimensions we originally measured her on. I'll print out\n",
    "# the columns too for reference:\n",
    "print x2.columns\n",
    "print x_std2[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.91860049 -0.1214413  -0.39708761  0.53065742  0.15286599  0.24653608\n",
      "  1.39188958  1.03065442 -0.35901289  0.62069226 -0.45271811 -0.59054281\n",
      "  0.00220306]\n",
      "Just PC1: -1.91860049167\n"
     ]
    }
   ],
   "source": [
    "# This is your first person transformed into the principal component coordinate system that PCA finds.\n",
    "# It's important to note here that the first value/column PC1 does NOT correspond directly to \"gender\"\n",
    "# from above. It is a new variable comprised of some weighted combination of all our original variables.\n",
    "# So, if this were shallowness, for example, it's some combination of gender, goal, go_out, etc. All the\n",
    "# original variables contribute to this shallowness rating, to different degrees.\n",
    "print test_pca[0,:]\n",
    "#\n",
    "print 'Just PC1:', test_pca[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.29744168 -0.26013794  0.01679921 -0.34919753 -0.22123015  0.1375355\n",
      "  0.31490658  0.51683777 -0.27757533 -0.09286115  0.02792137 -0.33004347\n",
      " -0.30349594]\n"
     ]
    }
   ],
   "source": [
    "# Kind of confusing because the variable is called \"Principal Component 1\", but the weighting vector used to \n",
    "# combine the original columns is also labeled as \"component\". Sorry. In class I called the\n",
    "# component vector the eigenvector. It's eseentially the vector of weights that blueprints the transformation\n",
    "# of your original columns into the singular PC1 value.\n",
    "# \n",
    "# Let's print out the component vector for PC1 below:\n",
    "print components[0, :]\n",
    "\n",
    "# Note here that the components matrix that comes out of sklearn has the component vectors\n",
    "# for each principal component organized in rows. So: rows are the vectors for each principal \n",
    "# component, and columns are the weights you multiply each of our original columns by before\n",
    "# summing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL COLUMN/VARIABLE VALUES:\n",
      "          original_value\n",
      "gender         -1.020433\n",
      "imprelig        0.035537\n",
      "goal           -0.163380\n",
      "date            1.345134\n",
      "go_out         -0.874156\n",
      "exphappy       -1.533837\n",
      "expnum         -0.749638\n",
      "attr1_1        -0.666877\n",
      "sinc1_1         0.434098\n",
      "intel1_1       -0.242618\n",
      "fun1_1         -0.359126\n",
      "amb1_1          0.722363\n",
      "shar1_1         0.621657\n",
      "-----------------------------------\n",
      "\n",
      "MATCH WITH PC1'S COMPONENT VECTOR (WEIGHTS FOR ORIGINAL VARS):\n",
      "          original_value  PC1_component_vector\n",
      "gender         -1.020433              0.297442\n",
      "imprelig        0.035537             -0.260138\n",
      "goal           -0.163380              0.016799\n",
      "date            1.345134             -0.349198\n",
      "go_out         -0.874156             -0.221230\n",
      "exphappy       -1.533837              0.137536\n",
      "expnum         -0.749638              0.314907\n",
      "attr1_1        -0.666877              0.516838\n",
      "sinc1_1         0.434098             -0.277575\n",
      "intel1_1       -0.242618             -0.092861\n",
      "fun1_1         -0.359126              0.027921\n",
      "amb1_1          0.722363             -0.330043\n",
      "shar1_1         0.621657             -0.303496\n",
      "-----------------------------------\n",
      "\n",
      "MULTIPLY ORIGINAL VAR VALUES WITH COMPONENT VECTOR WEIGHTS:\n",
      "          original_value  PC1_component_vector  component_pieces_of_PC1\n",
      "gender         -1.020433              0.297442                -0.303519\n",
      "imprelig        0.035537             -0.260138                -0.009244\n",
      "goal           -0.163380              0.016799                -0.002745\n",
      "date            1.345134             -0.349198                -0.469717\n",
      "go_out         -0.874156             -0.221230                 0.193390\n",
      "exphappy       -1.533837              0.137536                -0.210957\n",
      "expnum         -0.749638              0.314907                -0.236066\n",
      "attr1_1        -0.666877              0.516838                -0.344667\n",
      "sinc1_1         0.434098             -0.277575                -0.120495\n",
      "intel1_1       -0.242618             -0.092861                 0.022530\n",
      "fun1_1         -0.359126              0.027921                -0.010027\n",
      "amb1_1          0.722363             -0.330043                -0.238411\n",
      "shar1_1         0.621657             -0.303496                -0.188670\n",
      "-----------------------------------\n",
      "\n",
      "SUM THE PC1 COMPONENT PIECES TOGETHER TO GET VALUE FOR NEW VAR PC1:\n",
      "person 1 PC1 value: -1.91860049167\n",
      "-----------------------------------\n",
      "\n",
      "So again, the new PC1 variable is some linear combination of our original variables!\n",
      "\n",
      "We can get this same value out of the PCA object you fit on your original data:\n",
      "-1.91860049167\n",
      "...Which is the first row of the first column, aka PC1 value for person 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.9186004916669255"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do we get one value for our new variable PC1 from our old variables?\n",
    "# Remember that the new variable (PC1) is some weighted combination of our\n",
    "# old variables...\n",
    "# \n",
    "# So we have the original variables for person 1, which I'll print again.\n",
    "# We also have the component vector for PC1, which are the weights for our\n",
    "# original columns – we will multiply each value for this person in each\n",
    "# original column by it's corresponding \"weight\" in the component vector for\n",
    "# PC1.\n",
    "#\n",
    "# Lastly, we sum together all these \"reweighted\" values of our original \n",
    "# variables into the NEW value for variable PC1.\n",
    "\n",
    "print 'ORIGINAL COLUMN/VARIABLE VALUES:'\n",
    "person1 = pd.DataFrame({'original_value':x_std2[0,:]}, index=x2.columns)\n",
    "print person1\n",
    "print '-----------------------------------\\n'\n",
    "\n",
    "print \"MATCH WITH PC1'S COMPONENT VECTOR (WEIGHTS FOR ORIGINAL VARS):\"\n",
    "person1['PC1_component_vector'] = components[0, :]\n",
    "print person1\n",
    "print '-----------------------------------\\n'\n",
    "\n",
    "print \"MULTIPLY ORIGINAL VAR VALUES WITH COMPONENT VECTOR WEIGHTS:\"\n",
    "person1['component_pieces_of_PC1'] = person1.original_value*person1.PC1_component_vector\n",
    "print person1\n",
    "print '-----------------------------------\\n'\n",
    "\n",
    "print \"SUM THE PC1 COMPONENT PIECES TOGETHER TO GET VALUE FOR NEW VAR PC1:\"\n",
    "print 'person 1 PC1 value:',person1.component_pieces_of_PC1.sum()\n",
    "print '-----------------------------------\\n'\n",
    "\n",
    "print 'So again, the new PC1 variable is some linear combination of our original variables!\\n'\n",
    "\n",
    "print 'We can get this same value out of the PCA object you fit on your original data:'\n",
    "print test_pca[0,0]\n",
    "print '...Which is the first row of the first column, aka PC1 value for person 1.'\n",
    "\n",
    "\n",
    "np.sum(x_std2[0,:]*components.T[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now lets get the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = list(x2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values_df = pd.DataFrame(values, columns = col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "\n",
    "logistic2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y2b = np.ravel(y2)\n",
    "y2b = y2b.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvs = cross_val_score(logistic2, x_std2, y2b, cv = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
