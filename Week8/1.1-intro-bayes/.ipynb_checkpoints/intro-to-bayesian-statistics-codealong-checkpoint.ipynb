{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Bayesian Statistics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return to Frequentist vs. Bayesian\n",
    "\n",
    "To jump into bayesian statistics, we'll return to the difference between Frequentists and Bayesians\n",
    "\n",
    "Recall from the beginning of the course that:\n",
    "\n",
    "**Frequentists** believe the \"true\" distribution is fixed (and not known). We can infer more more about this \"true\" distribution by engaging in sampling, testing for effects, and studying relevant parameters of the population.\n",
    "\n",
    "**Bayesians** believe that data informs us about the distribution, and as we receive more data our view of the distribution can be updated, further confirming or denying our previous beliefs (but never in certainty).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Interpretations of probability\n",
    "\n",
    "**FREQUENTIST PROBABILITY** \n",
    "\n",
    "Probability is the true number of \"successes\" or \"positive occurrances\" measured across the hypothetical infinite number of samples/events/trials:\n",
    "\n",
    "### $$p = \\lim_{n \\to +\\infty} \\frac{k}{n}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$p$ is the probability of an occurance.\n",
    "\n",
    "$k$ is the number of occurances.\n",
    "\n",
    "$n$ is the number of events.\n",
    "\n",
    "---\n",
    "\n",
    "**BAYESIAN PROBABILITY**\n",
    "\n",
    "Probability is a representation of our uncertainty given what we know and believe to be true. Given a number of observed positive occurances over a number of events *and our prior belief about the true probability of positive occurances,* what is the *distribution of the true probability*?\n",
    "\n",
    "### $$P\\left(\\;true\\;|\\;observed\\;\\right) = \\frac{P\\left(\\;observed\\;|\\;true\\;\\right)}{P(\\;observed\\;)} P\\left(\\;true\\;\\right)$$\n",
    "\n",
    "where:\n",
    "\n",
    "$P\\left(\\;true\\;|\\;observed\\;\\right)$ is the **posterior probability** or **conditional probability**. This is the probability of an occurance given what we observed.\n",
    "\n",
    "$P\\left(\\;observed\\;|\\;true\\;\\right)$ is the **likelihood,** which is the probability of what we observed  given our prior belief about the probability of occurance. \n",
    "\n",
    "${P(\\;observed\\;)}$ is the **total probability** of the observed data. \n",
    "\n",
    "$P\\left(\\;true\\;\\right)$ is the **prior probability** belief. It is what you thought the probability was before observing the events.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' theorem\n",
    "\n",
    "Some of you might recognize the above formula as Bayes' theorem. Typically Bayes' theorem is written:\n",
    "\n",
    "### $$P\\left(\\;A\\;|\\;B\\;\\right) = \\frac{P\\left(\\;B\\;|\\;A\\;\\right)P\\left(\\;A\\;\\right)}{P(\\;B\\;)}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$A$ and $B$ are anything that take probabilities (which is essentially everything).\n",
    "\n",
    "$P(B|A)$ and $P(A|B)$ are the probabilities of $B$ conditional on $A$ and vice versa.\n",
    "\n",
    "This is just another way of writing:\n",
    "\n",
    "### $$P\\left(\\;A\\;\\right)P\\left(\\;B\\;|\\;A\\;\\right) = P\\left(\\;B\\;\\right)P\\left(\\;A\\;|\\;B\\;\\right)$$\n",
    "\n",
    "Which is derived from the fact that:\n",
    "\n",
    "### $$P\\left(\\;A\\;\\cap\\;B\\right) = P\\left(\\;A\\;\\right)P\\left(\\;B\\;|\\;A\\;\\right) = P\\left(\\;B\\;\\right)P\\left(\\;A\\;|\\;B\\;\\right)$$\n",
    "\n",
    "Where $P\\left(\\;A\\;\\cap\\;B\\right)$ is the probability of $A$ *and* $B$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denominator of Bayes' theorem: the \"total probability\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7gAAAHiCAIAAABN0fe0AAAAAXNSR0IArs4c6QAAAARnQU1BAACx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\nf2QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./assets/images/output_27_0.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above picture, we see that each $A_1,..., A_5$ includes a piece of the center oval. In this example the oval represents $B$.\n",
    "\n",
    "Basic probability defines the following relation: $$P(A|B) = \\frac{ A \\cap B }{B}$$ \n",
    "\n",
    "Intuitively, the relation indicates is that $P(A|B)$ is a ratio of the part of A that is common with B, *over the entirety of $B$*. \n",
    "\n",
    "Therefore, **the total probability can be thought of as the exhaustive sum of all probabilities on sets that share elements with B**. This equals simply the probability of B in our set of events.\n",
    "\n",
    "So what is the purpose of the total probability with respect to the rest of Bayes formula? **In essence, it \"normalizes\" the numerator into a quantity between 0 and 1,** ensuring the left side of the formula is a probability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving probability using Bayes' theorem is easy when you know $P(B)$\n",
    "\n",
    "Let's say we have two coins. Coin **FAIR** and coin **RIGGED**\n",
    "\n",
    "    coin FAIR has a 50% chance of flipping heads.\n",
    "    coin RIGGED has 99% chance of flipping heads.\n",
    "    \n",
    "Your friend chooses one of the two coins at random. He flips the coin and gets heads. \n",
    "\n",
    "What is the probability that the coin flipped was **FAIR**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bayes' theorem in the context of statistical modeling\n",
    "\n",
    "We can also interpret the equations above in the context of statistical modeling, which we've been doing tons of in this class:\n",
    "\n",
    "### $$P\\left(\\;model\\;|\\;data\\;\\right) = \\frac{P\\left(\\;data\\;|\\;model\\;\\right)}{P(\\;data\\;)} P\\left(\\;model\\;\\right)$$\n",
    "\n",
    "Or in plain english:\n",
    "\n",
    "**What is the probability of our model being true, given the data we have? This depends on the likelihood of the observed data given our model and the data iself, as well as our prior belief that this model is true.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin toss problem\n",
    "\n",
    "Say we flip a coin 100 times get heads 58 times. \n",
    "\n",
    "What's the probability that the coin is not fair?\n",
    "\n",
    "We can actually solve the probability of getting at least this many heads given a probability of 0.5 directly using the **binomial probability formula:**\n",
    "\n",
    "### $$P(\\;\\text{at least k heads in n flips}\\;) = \\sum_{k}^n\\binom{n}{k}p^kq^{n-k}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$n$ is the number of flips.\n",
    "\n",
    "$k$ is the number of heads.\n",
    "\n",
    "$p$ is the probability of heads.\n",
    "\n",
    "$q$ is the probability of tails.\n",
    "\n",
    "$\\binom{n}{k}$ describes \"n choose k\" or the possible **combinations of k instances in n events**:\n",
    "\n",
    "### $$\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$$\n",
    "\n",
    "---\n",
    "\n",
    "**Calculate the probability of 71 heads in 100 flips with a probability of heads = 0.5.**\n",
    "\n",
    "NOTE: Factorials can be calculated with `np.math.factorial()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequentist model testing\n",
    "\n",
    "Again, say we flip a coin 100 times get heads 61 times. \n",
    "\n",
    "We want to test whether it is rigged with a Frequentist statistical model.\n",
    "\n",
    "Recall that Frequentists construct a **null hypothesis** and an **alternative hypothesis**.\n",
    "\n",
    "**NULL HYPOTHESIS H0:** The coin is fair. P(heads) = 0.5\n",
    "\n",
    "**ALTERNATIVE HYPOTHESIS HA:** The coin is not fair. P(heads) != 0.5\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Central Limit Theorem, z-score, and z-test\n",
    "\n",
    "The theory behind what makes the calculations for Frequentist hypothesis testing conveniently easy is the Central Limit Theorem.\n",
    "\n",
    "**CENTRAL LIMIT THEOREM:**\n",
    "\n",
    "The mean of a sufficiently large number of iterations of independent random variables will be normally distributed, regardless of the underlying distribution of the random variable.\n",
    "\n",
    "For example, if random samples of people from a population are taken and their mean height is calculated, the calculated mean heights of all of those random samples will all along a normal distribution of mean heights.\n",
    "\n",
    "---\n",
    "\n",
    "**THE Z-SCORE:**\n",
    "\n",
    "A **z-score** is a normalized difference between a measured quantity and the quantity's expected value. It isdefined as:\n",
    "\n",
    "### $$ z = \\frac{\\bar{x} - E[x]}{std(\\bar{x})}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$\\bar{x}$ is the empirical (observed) quantity/measurement.\n",
    "\n",
    "$E[x]$ is the expected value of the quantity.\n",
    "\n",
    "$std(\\bar{x})$ is the empirical standard deviation of the quantity.\n",
    "\n",
    "---\n",
    "\n",
    "**THE Z-TEST**\n",
    "\n",
    "The z-test is the standard Frequentist hypothesis test that gives us a **p-value** (significance) of our measurement. It's validity depends on the Central Limit Theorem.\n",
    "\n",
    "A (two-tailed) p-value is calculated as:\n",
    "\n",
    "### $$\\text{p-value} = P[|z| > z_0] = 2P[z > z_0] = 2(1 - \\Phi(z_0))$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$z_0$ is our measured z-value.\n",
    "\n",
    "$P[|z| > z_0]$ is the probability that the absolute value of z-value is larger than our measured z-value.\n",
    "\n",
    "$2(1-\\Phi(z_0))$ is 2 times 1 minus the cumulative distribution function (CDF) of the normal distribution at point $z_0$.\n",
    "\n",
    "Because the CDF is valued between 0 and 1, essentially **the p-value is the proportion of z-values that are larger than our z-value.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://ipython-books.github.io/images/gaussian.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Coding the z-test\n",
    "\n",
    "We have:\n",
    "\n",
    "    100 coin flips\n",
    "    58 heads\n",
    "    \n",
    "Our hypotheses are:\n",
    "\n",
    "    Null hypothesis H0: probability of heads is 0.5\n",
    "    Alternative hypothesis HA: probability of heads is not 0.5\n",
    "    \n",
    "We want to find the probability that we got 71 heads given that our null hypothesis is true (the p-value).\n",
    "\n",
    "Under the null hypothesis H0:\n",
    "\n",
    "    E[x] = 0.5*flips\n",
    "    Var(x) = (flips * P(heads) * (1 - P(heads))\n",
    "    \n",
    "NOTE: The variance is defined as such because coin flips are part of the [Bernoulli distribution](http://mathworld.wolfram.com/BernoulliDistribution.html).\n",
    "\n",
    "**Calculate the p-value below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bayesian model testing\n",
    "\n",
    "Now let's look at the same scenario but from the Bayesian perspective. \n",
    "\n",
    "### $$P\\left(\\;bias\\;|\\;observations\\;\\right) = \\frac{P\\left(\\;observations\\;|\\;bias\\;\\right)}{P(\\;data\\;)} P\\left(\\;bias\\;\\right)$$\n",
    "\n",
    "Where $P\\left(\\;bias\\;\\right)$ is the **probability distribution** of getting heads when the coin is flipped.\n",
    "\n",
    "---\n",
    "\n",
    "**A UNIFORM PRIOR**\n",
    "\n",
    "You may think we'd assign $P\\left(\\;bias\\;\\right) = 0.5$, but that's not actually correct. This actually specifies a distribution of possible biases for our coin, with some biases potentially having a higher probability than others. \n",
    "\n",
    "Unlike when we were using Bayes formula before, we no longer know the true probability of heads, we just have a *distribution of beliefs* about what it might be.\n",
    "\n",
    "If we have no idea, we can set our prior distribution $P\\left(\\;bias\\;\\right)$ to be a **uniform prior**. This indicates that we have no belief about the weighting of the coin whatsoever. We believe all potential biases and thus probabilities of flipping heads between 0 and 1 are equally likely.\n",
    "\n",
    "With a uniform prior distribution, we set $P\\left(\\;bias\\;\\right) = 1$, which will give all possible biases exactly the same probability. (Imagine a \"distribution\" that is just a flat line.)\n",
    "\n",
    "---\n",
    "\n",
    "**THE LIKELIHOOD**\n",
    "\n",
    "Luckily, we have already looked at the likelihood $P\\left(\\;observations\\;|\\;bias\\;\\right)$ earlier. It is the binomial probability function:\n",
    "\n",
    "### $$P\\left(\\;observations\\;|\\;bias\\;\\right) = \\binom{flips}{heads}bias^{heads}(1-bias)^{flips-heads}$$\n",
    "\n",
    "This likelihood is the probability distribution of the observations given different biases.\n",
    "\n",
    "---\n",
    "\n",
    "**THE PROBABILITY OF THE DATA**\n",
    "\n",
    "This is the most difficult part to understand (in my opinion)\n",
    "\n",
    "$P\\left(\\;data\\;\\right)$ is not in just the proportion of heads in the observations. This too is a probability distribution rather than a discrete probability.\n",
    "\n",
    "It turns out that $P\\left(\\;data\\;\\right)$ is **the probability of the data regardless of what the bias is.** We do this by integrating over all possible biases from 0 to 1:\n",
    "\n",
    "### $$P\\left(\\;observations\\;\\right) = \\int_{i=0}^1P\\left(\\;observations\\;|\\;bias\\;\\right)P\\left(\\;bias\\;\\right)\\partial bias$$\n",
    "\n",
    "Really this ends up just being a \"normalizing factor\" that makes sure the likelihood probability distribution integrates to 1. \n",
    "\n",
    "In other words this is **the chance of this many heads across all biases.**\n",
    "\n",
    "---\n",
    "\n",
    "**THE POSTERIOR PROBABILITY DISTRIBUTION**\n",
    "\n",
    "Due to nice properties of the binomial distribution and our uniform prior, this gets conveniently solved to a tidy equation below (I am not going to go over how or why, [but you can look it up online](http://ipython-books.github.io/featured-07/)). \n",
    "\n",
    "Keep in mind that tidy solutions to posteriors are pretty rare, an issue we will discuss later. \n",
    "\n",
    "### $$P\\left(\\;bias\\;|\\;observations\\;\\right) = \\frac{\\binom{flips}{heads}bias^{heads}(1-bias)^{flips-heads}}{\\int_{i=0}^1P\\left(\\;observations\\;|\\;bias\\;\\right)P\\left(\\;bias\\;\\right)\\partial bias}$$\n",
    "\n",
    "### $$P\\left(\\;bias\\;|\\;observations\\;\\right) = (flips + 1)\\binom{flips}{heads}bias^{heads}(1-bias)^{flips-heads}$$\n",
    "\n",
    "**Remember: this is a probability distribution of our bias given the data!**\n",
    "\n",
    "---\n",
    "\n",
    "**Code the posterior and plot it below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('white')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import scipy's combination function\n",
    "from scipy.misc import comb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Good references and sources I modeled this off of:\n",
    "\n",
    "http://ipython-books.github.io/featured-07/\n",
    "\n",
    "http://stats.stackexchange.com/questions/31867/bayesian-vs-frequentist-interpretations-of-probability\n",
    "\n",
    "http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/\n",
    "\n",
    "https://simple.wikipedia.org/wiki/Bayes%27_theorem\n",
    "\n",
    "https://en.wikipedia.org/wiki/Central_limit_theorem\n",
    "\n",
    "http://www.cogsci.ucsd.edu/classes/SP07/COGS14/NOTES/binomial_ztest.pdf\n",
    "\n",
    "https://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors\n",
    "\n",
    "https://arbital.com/p/bayes_rule/?l=1zq\n",
    "\n",
    "https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/\n",
    "\n",
    "http://www.yudkowsky.net/rational/bayes/\n",
    "\n",
    "http://people.stern.nyu.edu/wgreene/MathStat/Notes-2-BayesianStatistics.pdf\n",
    "\n",
    "http://stats.stackexchange.com/questions/58564/help-me-understand-bayesian-prior-and-posterior-distributions\n",
    "\n",
    "http://pages.uoregon.edu/cfulton/posts/bernoulli_trials_bayesian.html\n",
    "\n",
    "http://chrisstrelioff.ws/sandbox/2014/12/11/inferring_probabilities_with_a_beta_prior_a_third_example_of_bayesian_calculations.html\n",
    "\n",
    "https://www.chrisstucchio.com/blog/2013/magic_of_conjugate_priors.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
