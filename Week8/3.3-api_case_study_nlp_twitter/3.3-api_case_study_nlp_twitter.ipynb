{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "---\n",
    "title: API Review with Foursquare API\n",
    "type:  lesson + lab + demo\n",
    "duration: \"1:25\"\n",
    "creator:\n",
    "    name: David Yerrington\n",
    "    city: SF\n",
    "---\n",
    "```\n",
    "<img src=\"https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png\" style=\"float: left; margin: 10px\">\n",
    "\n",
    "#  API Demo / Lab + NLP\n",
    "Week 8 | 3.3\n",
    "\n",
    "\n",
    "<img src=\"https://snag.gy/RNAEgP.jpg\" width=\"600\">\n",
    "\n",
    "Can we correctly identify which of these two old men tweeted what?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5 mins) Opening \n",
    "\n",
    "Today we are going to attempt to classify wether a tweet comes from Trump, or Sanders.  We are going to:\n",
    "\n",
    "- Create a developer account on Twitter\n",
    "- Create a method to pull a list of tweets from the Twitter API\n",
    "- Perform proper preprocessing on our text\n",
    "- Engineer sentiment feature in our dataset using TextBlob\n",
    "- Explore supervised classification techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API Developer Registration\n",
    "\n",
    "If you haven't registered a Twitter account yet, this is a requirement in order to have a \"developer\" account.\n",
    "\n",
    "[Twitter Rest API](https://dev.twitter.com/rest/public)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an \"App\"\n",
    "\n",
    "![](https://snag.gy/HPBQbJ.jpg)\n",
    "\n",
    "We now will now go to Twitter and register an \"app\" [apps.twitter.com](https://apps.twitter.com/), just like we did for Foursquare.  After we set up our app, we will only need to reference the cooresponding keys Twitter generates for our app.  These are the keys that we will use with our application to communicate with the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python Twitter API library\n",
    "\n",
    "Someone was nice enough to build a nice libary for us in Python that we only need to plug in our keys and start collecting data with.  The library we will be using is provided by [Python Twitter Tools](http://mike.verdone.ca/twitter/).\n",
    "\n",
    "To install it, just run the next frame (there is no conda package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twitter\n",
      "  Downloading twitter-1.17.1-py2.py3-none-any.whl (55kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 785kB/s \n",
      "\u001b[?25hCollecting python-twitter\n",
      "  Downloading python-twitter-3.1.tar.gz (80kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 1.1MB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): future in /Users/sebozek/anaconda/lib/python2.7/site-packages (from python-twitter)\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests in /Users/sebozek/anaconda/lib/python2.7/site-packages (from python-twitter)\n",
      "Collecting requests-oauthlib (from python-twitter)\n",
      "  Downloading requests_oauthlib-0.6.1-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=0.6.2 (from requests-oauthlib->python-twitter)\n",
      "  Downloading oauthlib-1.1.2.tar.gz (111kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 1.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: python-twitter, oauthlib\n",
      "  Running setup.py bdist_wheel for python-twitter ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/sebozek/Library/Caches/pip/wheels/22/1e/2e/506871fa7dc610616948e70812d5e2518cd89c13f757b98f6c\n",
      "  Running setup.py bdist_wheel for oauthlib ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/sebozek/Library/Caches/pip/wheels/e6/be/43/e4a2ca8cb9c78fbd9b5b14b96cb7a5cc43f36bc11af5dfac5b\n",
      "Successfully built python-twitter oauthlib\n",
      "Installing collected packages: twitter, oauthlib, requests-oauthlib, python-twitter\n",
      "Successfully installed oauthlib-1.1.2 python-twitter-3.1 requests-oauthlib-0.6.1 twitter-1.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install twitter python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Boring Twitter Rules\n",
    "\n",
    "Twitter says they will rate limit your requests:\n",
    "\n",
    ">When using application-only authentication, rate limits are determined globally for the entire application. If a method allows for 15 requests per rate limit window, then it allows you to make 15 requests per window — on behalf of your application. This limit is considered completely separately from per-user limits. https://dev.twitter.com/rest/public/rate-limiting\n",
    "\n",
    "Here's a quick overview of what Twitter says are \"the rulez\":\n",
    "\n",
    "![](https://snag.gy/yJ6vIH.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About those Keys: OAuth Review\n",
    "\n",
    "![](https://g.twimg.com/dev/documentation/image/appauth_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's going on here?  Take a minute.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Application Keys\n",
    "\n",
    "Take note of our application keys that we will be using with our little application that will be connecting to Twitter and mining Tweets from the official Bernie Sanders and Donald Trump twitter accounts.\n",
    "\n",
    "![](https://snag.gy/H1djQK.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Miner Class Setup\n",
    "\n",
    "The following code is meant to get us up and running with connectivity to twitter, and the ability to make requests and easily transform the JSON responses to DataFrames.  We will be using object oriented Python in order to organize our code.  We may go into review since this was a topic we covered earlier in the class but we can review it during the lab for those who want to know more about it.\n",
    "\n",
    "\n",
    "> \"request_limit\" is used in this class to limit the number of tweets that are pulled per instance request.  Setting it to something lower until you've worked the bugs out of your request, and captured the data you want, is essential to avoiding any rate limit blocks.\n",
    "\n",
    "#### Key Setup\n",
    "\n",
    "- **consumer_key** - Find this in your app page under the \"Keys and Access Tokens\"\n",
    "- **consumer_secret** - Right under **consumer_key** in the \"Keys and Access Tokens\" tab\n",
    "- **access_token_key** - You will need to click the \"generate tokens\" button to get this\n",
    "- **access_token_secret** - Also available after \"generate tokens\" is pressed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import twitter, re, datetime, pandas as pd\n",
    "\n",
    "class twitterminer():\n",
    "\n",
    "    request_limit   =   20    \n",
    "    api             =   False\n",
    "    data            =   []\n",
    "    \n",
    "    twitter_keys = {\n",
    "        'consumer_key':        'qvWLs0mSiw9tRQWRLCmXE412N',\n",
    "        'consumer_secret':     'r9hGRjzgToCmBHaasgUDiImqjqS65kP7opTnXYUwDoVYoUbRi3',\n",
    "        'access_token_key':    '1887369426-X1nL75QFZA3PoK9NZqJSlSAqUYimfzav08uGyA2',\n",
    "        'access_token_secret': 'FlxLFVghY5ljqHgwoYg3ueSpuOudUZ8RaQXirusRUcTft'\n",
    "    }\n",
    "    \n",
    "    def __init__(self,  request_limit = 20):\n",
    "        \n",
    "        self.request_limit = request_limit\n",
    "        \n",
    "        # This sets the twitter API object for use internall within the class\n",
    "        self.set_api()\n",
    "        \n",
    "    def set_api(self):\n",
    "        \n",
    "        self.api = twitter.Api(\n",
    "            consumer_key         =   self.twitter_keys['consumer_key'],\n",
    "            consumer_secret      =   self.twitter_keys['consumer_secret'],\n",
    "            access_token_key     =   self.twitter_keys['access_token_key'],\n",
    "            access_token_secret  =   self.twitter_keys['access_token_secret']\n",
    "        )\n",
    "\n",
    "    def mine_user_tweets(self, user=\"dyerrington\", mine_rewteets=False):\n",
    "\n",
    "        statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.request_limit)\n",
    "        data       =   []\n",
    "        \n",
    "        for item in statuses:\n",
    "\n",
    "            mined = {\n",
    "                'tweet_id': item.id,\n",
    "                'handle': item.user.name,\n",
    "                'retweet_count': item.retweet_count,\n",
    "                'text': item.text,\n",
    "                'mined_at': datetime.datetime.now(),\n",
    "                'created_at': item.created_at,\n",
    "            }\n",
    "            \n",
    "            data.append(mined)\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does anyone remember how we \"instantiate\" a new instance of this class?\n",
    "\n",
    "**Bonus bonus** How do we call the method to *mine_user_tweets()*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'created_at': u'Wed Jun 01 13:17:58 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52157),\n",
       "  'retweet_count': 5415,\n",
       "  'text': u'So I raised/gave $5,600,000 for the veterans and the media makes me look bad! They do anything to belittle - totally biased.',\n",
       "  'tweet_id': 737996614573260800},\n",
       " {'created_at': u'Tue May 31 23:18:28 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52167),\n",
       "  'retweet_count': 4049,\n",
       "  'text': u'Congratulations to @seanhannity on his tremendous increase in television ratings. Speaking of ratings- I will be on his show tonight @ 10pE.',\n",
       "  'tweet_id': 737785345459113985},\n",
       " {'created_at': u'Tue May 31 23:17:33 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52169),\n",
       "  'retweet_count': 5895,\n",
       "  'text': u'I am getting great credit for my press conference today. Crooked Hillary should be admonished for not having a press conference in 179 days.',\n",
       "  'tweet_id': 737785114239864832},\n",
       " {'created_at': u'Tue May 31 23:14:42 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52172),\n",
       "  'retweet_count': 5776,\n",
       "  'text': u'Katie Couric, the third rate reporter, who has been largely forgotten, should be ashamed of herself for the fraudulent editing of her doc.',\n",
       "  'tweet_id': 737784398515441664},\n",
       " {'created_at': u'Tue May 31 22:51:56 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52174),\n",
       "  'retweet_count': 2140,\n",
       "  'text': u'I will be interviewed on @seanhannity tonight at 10pmE on @FoxNews. Enjoy!',\n",
       "  'tweet_id': 737778668785766404},\n",
       " {'created_at': u'Tue May 31 21:12:07 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52176),\n",
       "  'retweet_count': 2934,\n",
       "  'text': u'Join me in Sacramento, California-tomorrow evening @ 7pm! #Trump2016\\nhttps://t.co/W7xy7eXcii https://t.co/km0rRYSDnO',\n",
       "  'tweet_id': 737753549564694528},\n",
       " {'created_at': u'Tue May 31 16:57:17 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52178),\n",
       "  'retweet_count': 5156,\n",
       "  'text': u'So many veterans groups are beyond happy with all of the money I raised/gave! It was my great honor - they do an amazing job.',\n",
       "  'tweet_id': 737689416811073536},\n",
       " {'created_at': u'Tue May 31 16:53:58 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52181),\n",
       "  'retweet_count': 5225,\n",
       "  'text': u'Just finished a press conference in Trump Tower wherein I gave information on which VETERANS groups got the $5,600,000 that I raised/gave!',\n",
       "  'tweet_id': 737688582849171456},\n",
       " {'created_at': u'Tue May 31 11:42:20 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52182),\n",
       "  'retweet_count': 5280,\n",
       "  'text': u'I have raised/given a tremendous amount of money to our great VETERANS, and have got nothing but bad publicity for doing so. Watch!',\n",
       "  'tweet_id': 737610159459991552},\n",
       " {'created_at': u'Tue May 31 10:48:49 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52185),\n",
       "  'retweet_count': 3903,\n",
       "  'text': u'So many great things happening - new poll numbers looking good! News conference at 11:00 A.M. today, Trump Tower!',\n",
       "  'tweet_id': 737596690257969152},\n",
       " {'created_at': u'Mon May 30 21:55:41 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52187),\n",
       "  'retweet_count': 3868,\n",
       "  'text': u'I should have easily won the Trump University case on summary judgement but have a judge, Gonzalo Curiel, who is totally biased against me.',\n",
       "  'tweet_id': 737402123453878272},\n",
       " {'created_at': u'Mon May 30 21:45:09 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52189),\n",
       "  'retweet_count': 3680,\n",
       "  'text': u'I have a judge in the Trump University civil case, Gonzalo Curiel (San Diego), who is very unfair. An Obama pick. Totally biased-hates Trump',\n",
       "  'tweet_id': 737399475509985280},\n",
       " {'created_at': u'Mon May 30 20:15:04 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52191),\n",
       "  'retweet_count': 5238,\n",
       "  'text': u'I hope everyone had a great Memorial Day!',\n",
       "  'tweet_id': 737376803514286081},\n",
       " {'created_at': u'Mon May 30 20:13:17 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52193),\n",
       "  'retweet_count': 4855,\n",
       "  'text': u'I would have had millions of votes more in the primaries (than Crooked Hillary) if I only had one opponent, instead of sixteen. Broke record',\n",
       "  'tweet_id': 737376356795875330},\n",
       " {'created_at': u'Mon May 30 11:26:47 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52194),\n",
       "  'retweet_count': 9384,\n",
       "  'text': u'Have a great Memorial Day and remember that we will soon MAKE AMERICA GREAT AGAIN!',\n",
       "  'tweet_id': 737243856144629760},\n",
       " {'created_at': u'Mon May 30 11:20:38 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52196),\n",
       "  'retweet_count': 2636,\n",
       "  'text': u'\"@NBCDFW: Trump rallies veterans at annual Rolling Thunder Gathering https://t.co/b08FcMlgkr https://t.co/RCDeLvHQqD\"',\n",
       "  'tweet_id': 737242308261842945},\n",
       " {'created_at': u'Mon May 30 11:20:09 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52198),\n",
       "  'retweet_count': 1528,\n",
       "  'text': u'\"@FrankyLamouche: how many of donald\\'s rolling thunder brigade will sign up and go to war for him in the middle east.\"',\n",
       "  'tweet_id': 737242189055594496},\n",
       " {'created_at': u'Mon May 30 11:19:29 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52200),\n",
       "  'retweet_count': 4049,\n",
       "  'text': u'\"@MariaErnandez3b: Trump Supports Rolling Thunder Rally #TRUMP STRONG https://t.co/pfVXQ8NdZu\" So true, and remember the M.I.A.\\'s!',\n",
       "  'tweet_id': 737242018687164416},\n",
       " {'created_at': u'Mon May 30 11:17:04 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52202),\n",
       "  'retweet_count': 2060,\n",
       "  'text': u'\"@ScottWRasmussen: Donald Trump and Bikers Share Affection at Rolling Thunder Rally https://t.co/ZZl2sc29dn\" A great day in D.C.!',\n",
       "  'tweet_id': 737241411465170944},\n",
       " {'created_at': u'Mon May 30 11:10:12 +0000 2016',\n",
       "  'handle': u'Donald J. Trump',\n",
       "  'mined_at': datetime.datetime(2016, 6, 1, 11, 0, 5, 52203),\n",
       "  'retweet_count': 3370,\n",
       "  'text': u'\"@TeaPartyNevada: #Trump2016 \"Illegals are taken care of better than our veterans.\"  https://t.co/KKIgM4rNma https://t.co/1cEZ8wG7Cy\"',\n",
       "  'tweet_id': 737239685295181824}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# twitter ids:  realDonaldTrump, berniesanders\n",
    "# Let's test this out here..\n",
    "\n",
    "twit = twitterminer() # Instantiate a new instance of the class\n",
    "\n",
    "twit.mine_user_tweets(user='realDonaldTrump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Now we create some training data\n",
    "\n",
    "We will have to munge a little bit in order to get our \"mined\" data from the Twitter API.  \n",
    "\n",
    " - Mine Trump Tweets\n",
    " - Create DataFrame\n",
    " - Mine Sanders Tweets\n",
    " - Append to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we only need to \"instantiate\" once.  Then we can call mine_user_tweets as much as we want.\n",
    "miner = twitterminer(request_limit=100)\n",
    "trump_tweets = miner.mine_user_tweets(\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Jun 01 13:17:58 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884034</td>\n",
       "      <td>5422</td>\n",
       "      <td>So I raised/gave $5,600,000 for the veterans a...</td>\n",
       "      <td>737996614573260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue May 31 23:18:28 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884051</td>\n",
       "      <td>4049</td>\n",
       "      <td>Congratulations to @seanhannity on his tremend...</td>\n",
       "      <td>737785345459113985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue May 31 23:17:33 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884055</td>\n",
       "      <td>5895</td>\n",
       "      <td>I am getting great credit for my press confere...</td>\n",
       "      <td>737785114239864832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue May 31 23:14:42 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884058</td>\n",
       "      <td>5777</td>\n",
       "      <td>Katie Couric, the third rate reporter, who has...</td>\n",
       "      <td>737784398515441664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue May 31 22:51:56 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884060</td>\n",
       "      <td>2140</td>\n",
       "      <td>I will be interviewed on @seanhannity tonight ...</td>\n",
       "      <td>737778668785766404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tue May 31 21:12:07 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884064</td>\n",
       "      <td>2934</td>\n",
       "      <td>Join me in Sacramento, California-tomorrow eve...</td>\n",
       "      <td>737753549564694528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tue May 31 16:57:17 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884067</td>\n",
       "      <td>5156</td>\n",
       "      <td>So many veterans groups are beyond happy with ...</td>\n",
       "      <td>737689416811073536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tue May 31 16:53:58 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884070</td>\n",
       "      <td>5225</td>\n",
       "      <td>Just finished a press conference in Trump Towe...</td>\n",
       "      <td>737688582849171456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tue May 31 11:42:20 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884074</td>\n",
       "      <td>5280</td>\n",
       "      <td>I have raised/given a tremendous amount of mon...</td>\n",
       "      <td>737610159459991552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tue May 31 10:48:49 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:00:41.884079</td>\n",
       "      <td>3903</td>\n",
       "      <td>So many great things happening - new poll numb...</td>\n",
       "      <td>737596690257969152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at           handle                   mined_at  \\\n",
       "0  Wed Jun 01 13:17:58 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884034   \n",
       "1  Tue May 31 23:18:28 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884051   \n",
       "2  Tue May 31 23:17:33 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884055   \n",
       "3  Tue May 31 23:14:42 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884058   \n",
       "4  Tue May 31 22:51:56 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884060   \n",
       "5  Tue May 31 21:12:07 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884064   \n",
       "6  Tue May 31 16:57:17 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884067   \n",
       "7  Tue May 31 16:53:58 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884070   \n",
       "8  Tue May 31 11:42:20 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884074   \n",
       "9  Tue May 31 10:48:49 +0000 2016  Donald J. Trump 2016-06-01 11:00:41.884079   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0           5422  So I raised/gave $5,600,000 for the veterans a...   \n",
       "1           4049  Congratulations to @seanhannity on his tremend...   \n",
       "2           5895  I am getting great credit for my press confere...   \n",
       "3           5777  Katie Couric, the third rate reporter, who has...   \n",
       "4           2140  I will be interviewed on @seanhannity tonight ...   \n",
       "5           2934  Join me in Sacramento, California-tomorrow eve...   \n",
       "6           5156  So many veterans groups are beyond happy with ...   \n",
       "7           5225  Just finished a press conference in Trump Towe...   \n",
       "8           5280  I have raised/given a tremendous amount of mon...   \n",
       "9           3903  So many great things happening - new poll numb...   \n",
       "\n",
       "             tweet_id  \n",
       "0  737996614573260800  \n",
       "1  737785345459113985  \n",
       "2  737785114239864832  \n",
       "3  737784398515441664  \n",
       "4  737778668785766404  \n",
       "5  737753549564694528  \n",
       "6  737689416811073536  \n",
       "7  737688582849171456  \n",
       "8  737610159459991552  \n",
       "9  737596690257969152  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_df = pd.DataFrame(trump_tweets)\n",
    "trump_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Any interesting ngrams going on with Trump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'https co', 31),\n",
       " (u'thank you', 14),\n",
       " (u'crooked hillary', 10),\n",
       " (u'of the', 10),\n",
       " (u'trump2016 https', 8),\n",
       " (u'in the', 8),\n",
       " (u'for the', 6),\n",
       " (u'will be', 6),\n",
       " (u'great again', 5),\n",
       " (u'america great', 5)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "# With Stop Words\n",
    "\n",
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect = TfidfVectorizer( ngram_range=(2,2) )\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "summaries = \"\".join(trump_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'crooked hillary', 10),\n",
       " (u'trump2016 https', 8),\n",
       " (u'make america', 5),\n",
       " (u'america great', 5),\n",
       " (u'rolling thunder', 5),\n",
       " (u'hillary clinton', 5),\n",
       " (u'elizabeth warren', 4),\n",
       " (u'memorial day', 3),\n",
       " (u'totally biased', 3),\n",
       " (u'dishonest media', 3)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without Stop Words\n",
    "\n",
    "# We can use the TfidfVectorizer to find ngrams for us\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(2,2))\n",
    "\n",
    "# Pulls all of trumps tweet text's into one giant string\n",
    "summaries = \"\".join(trump_df['text'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10 mins) Try this exercize with Bernie Sanders.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sanders_tweets = miner.mine_user_tweets(\"berniesanders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Jun 01 18:04:31 +0000 2016</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2016-06-01 11:32:20.962080</td>\n",
       "      <td>361</td>\n",
       "      <td>We need to implement a nationwide ban on frack...</td>\n",
       "      <td>738068724356370432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Jun 01 17:07:42 +0000 2016</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2016-06-01 11:32:20.962091</td>\n",
       "      <td>348</td>\n",
       "      <td>We need to put an end to fracking all over thi...</td>\n",
       "      <td>738054427341402114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Jun 01 16:41:55 +0000 2016</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2016-06-01 11:32:20.962094</td>\n",
       "      <td>775</td>\n",
       "      <td>If I am elected president we will work togethe...</td>\n",
       "      <td>738047938681704450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Jun 01 16:24:02 +0000 2016</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2016-06-01 11:32:20.962097</td>\n",
       "      <td>898</td>\n",
       "      <td>Secretary Clinton and I have differences of op...</td>\n",
       "      <td>738043438021500928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Jun 01 14:58:07 +0000 2016</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>2016-06-01 11:32:20.962099</td>\n",
       "      <td>1061</td>\n",
       "      <td>When we pass Medicare for all, everyone will h...</td>\n",
       "      <td>738021814983491584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at          handle                   mined_at  \\\n",
       "0  Wed Jun 01 18:04:31 +0000 2016  Bernie Sanders 2016-06-01 11:32:20.962080   \n",
       "1  Wed Jun 01 17:07:42 +0000 2016  Bernie Sanders 2016-06-01 11:32:20.962091   \n",
       "2  Wed Jun 01 16:41:55 +0000 2016  Bernie Sanders 2016-06-01 11:32:20.962094   \n",
       "3  Wed Jun 01 16:24:02 +0000 2016  Bernie Sanders 2016-06-01 11:32:20.962097   \n",
       "4  Wed Jun 01 14:58:07 +0000 2016  Bernie Sanders 2016-06-01 11:32:20.962099   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0            361  We need to implement a nationwide ban on frack...   \n",
       "1            348  We need to put an end to fracking all over thi...   \n",
       "2            775  If I am elected president we will work togethe...   \n",
       "3            898  Secretary Clinton and I have differences of op...   \n",
       "4           1061  When we pass Medicare for all, everyone will h...   \n",
       "\n",
       "             tweet_id  \n",
       "0  738068724356370432  \n",
       "1  738054427341402114  \n",
       "2  738047938681704450  \n",
       "3  738043438021500928  \n",
       "4  738021814983491584  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanders_df = pd.DataFrame(sanders_tweets)\n",
    "sanders_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(\n",
    "                       ngram_range=(2,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'https co', 50),\n",
       " (u'need to', 8),\n",
       " (u'of the', 8),\n",
       " (u'this country', 6),\n",
       " (u'in the', 5),\n",
       " (u'we need', 5),\n",
       " (u'here https', 5),\n",
       " (u'tune in', 5),\n",
       " (u'on june', 4),\n",
       " (u'we are', 4)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make summary of the documents\n",
    "summary = \"\".join(sanders_df['text'])\n",
    "\n",
    "ngrams_summaries = vect.fit(sanders['text']).build_analyzer()(summary)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(2,2),\n",
    "                       stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_summaries = vect.fit(sanders_df['text']).build_analyzer()(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'climate change', 4),\n",
       " (u'bernie bernie', 4),\n",
       " (u'bernie sanders', 4),\n",
       " (u'health care', 4),\n",
       " (u'june https', 3),\n",
       " (u'wall street', 3),\n",
       " (u'social conversation', 3),\n",
       " (u'donald trump', 3),\n",
       " (u'live https', 3),\n",
       " (u'final fec', 2)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(ngrams_summaries).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tweets = pd.DataFrame(trump_tweets + sanders_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing our Tweets\n",
    "\n",
    "In order to do classfication recall that we need a set of features.  Our features are literally what our presidential hopefulls say on Twitter. \n",
    "\n",
    "We will need to:\n",
    "- Vectorize input text data\n",
    "- Intialize a model (let's try Logistic regression)\n",
    "- Train / Predict / Cross Validate\n",
    "- Score / Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Preprocess our text data to Tfidf\n",
    "tfv = TfidfVectorizer(lowercase=True, strip_accents='unicode')\n",
    "X_all = tfv.fit_transform(all_tweets['text'])\n",
    "\n",
    "# Setup logistic regression (or try another classification method here)\n",
    "estimator = LogisticRegression()\n",
    "estimator.fit(X_all, all_tweets['handle'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Prediction vs Random Sanders Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64385463  0.35614537]\n",
      " [ 0.29054443  0.70945557]]\n",
      "[u'Bernie Sanders' u'Donald J. Trump']\n"
     ]
    }
   ],
   "source": [
    "# Prep our source as TfIdf vectors\n",
    "source_test = [\n",
    "    \"Demanding that the wealthy and the powerful start paying their fair share of taxes that's exactly what the American people want.\",\n",
    "    \"Crooked Hillary is spending tremendous amounts of Wall Street money on false ads against me. She is a very dishonest person!\",\n",
    "]\n",
    "\n",
    "\n",
    "############\n",
    "# NOTE:  Do not re-initialize the tfidf vectorizor or the feature space willbe overwritten and\n",
    "# hence your transform will not match the number of features you trained your model on.\n",
    "#\n",
    "# This is why you only need to \"transform\" since you already \"fit\" previously\n",
    "#\n",
    "####\n",
    "\n",
    "X_all = tfv.transform(source_test)\n",
    "\n",
    "# Predict using previously trained logist regression `estimator`\n",
    "print estimator.predict_proba(X_all)\n",
    "print estimator.predict(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Time\n",
    "\n",
    "We would like you to perform an analysis using a proper cross validation.  Also, try classfication using other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implement the same analysis using more data.\n",
    "\n",
    "Experiment with using more data.  The API may not like that you are blowing through their limits so definitely be careful.  Try to grab only what you need 1x, then work on the copy of the objects that are returned.  Read the documents about rate limits and see if you can get enough without hitting the rate limit.  Are there any options availabl in the API to avoid such a problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we only need to \"instantiate\" once.  Then we can call mine_user_tweets as much as we want.\n",
    "miner = twitterminer(request_limit=200)\n",
    "trump_tweets = miner.mine_user_tweets(\"realDonaldTrump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "miner = twitterminer(request_limit=200)\n",
    "bernie_tweets = miner.mine_user_tweets(\"berniesanders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tweets = pd.DataFrame(trump_tweets + bernie_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 6)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bern_df = pd.DataFrame(bernie_tweets)\n",
    "trump_df = pd.DataFrame(trump_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(2,2), stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'political revolution', 9),\n",
       " (u'puerto rico', 9),\n",
       " (u'vote bernie', 7),\n",
       " (u'health care', 5),\n",
       " (u'wall street', 5),\n",
       " (u'donald trump', 5),\n",
       " (u'climate change', 5),\n",
       " (u'california https', 4),\n",
       " (u'bernie bernie', 4),\n",
       " (u'fossil fuel', 4)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern_n = vect.fit(bern_df.text).build_analyzer()(\"\".join(bern_df.text))\n",
    "\n",
    "Counter(bern_n).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'crooked hillary', 26),\n",
       " (u'hillary clinton', 13),\n",
       " (u'trump2016 https', 11),\n",
       " (u'megynkelly realdonaldtrump', 11),\n",
       " (u'failing nytimes', 7),\n",
       " (u'america great', 6),\n",
       " (u'make america', 6),\n",
       " (u'rolling thunder', 5),\n",
       " (u'close deal', 4),\n",
       " (u'rowanne brewer', 4)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_n = vect.fit(trump_df.text).build_analyzer()(\"\".join(trump_df.text))\n",
    "\n",
    "Counter(trump_n).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implement K-Folds or test/train split.\n",
    "\n",
    "Double check that you are getting random data before moving forward.  What would happen if you over sample Trump more than Sanders?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mine more Tweets that aren't in your data set\n",
    "Or use the hold-out method to do a proper test.  Refer back to our advanced classification evaluation lesson if you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check your classification report\n",
    "How's precision / recall of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.  Change out your TFIDF vectorizer for CountVectorizer.\n",
    "How has this impacted your mode performance at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.  Implement a different classification method such as random forrests.\n",
    "Or pick one of your favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.  Try to remove stopwords from your text during your preprocessing step\n",
    "\n",
    "Then double check your classfication report.  Have things improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  Try removing samples that have links or that are obviously just announcements or \"noise\" that doesn't appear to represent \"True\" tweets by the authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. What are some contrasting words or phrases that you can see between the ngrams for each author?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.  What do you think you can do to improve the scores further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. **BONUS** Using TextBlob, add a sentiment feature to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all_tweets['Sentiment'] = TextBlob(all_tweets['text']).sentiment\n",
    "\n",
    "all_tweets['Polarity'] = all_tweets['text'].apply(lambda x : TextBlob(x).sentiment.polarity)\n",
    "all_tweets['Subjectivity'] = all_tweets['text'].apply(lambda x : TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del all_tweets['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>handle</th>\n",
       "      <th>mined_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Jun 01 13:17:58 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:58:19.858409</td>\n",
       "      <td>5854</td>\n",
       "      <td>So I raised/gave $5,600,000 for the veterans a...</td>\n",
       "      <td>737996614573260800</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tue May 31 23:18:28 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:58:19.858421</td>\n",
       "      <td>4108</td>\n",
       "      <td>Congratulations to @seanhannity on his tremend...</td>\n",
       "      <td>737785345459113985</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tue May 31 23:17:33 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:58:19.858424</td>\n",
       "      <td>5960</td>\n",
       "      <td>I am getting great credit for my press confere...</td>\n",
       "      <td>737785114239864832</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue May 31 23:14:42 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:58:19.858426</td>\n",
       "      <td>5870</td>\n",
       "      <td>Katie Couric, the third rate reporter, who has...</td>\n",
       "      <td>737784398515441664</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tue May 31 22:51:56 +0000 2016</td>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2016-06-01 11:58:19.858428</td>\n",
       "      <td>2151</td>\n",
       "      <td>I will be interviewed on @seanhannity tonight ...</td>\n",
       "      <td>737778668785766404</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at           handle                   mined_at  \\\n",
       "0  Wed Jun 01 13:17:58 +0000 2016  Donald J. Trump 2016-06-01 11:58:19.858409   \n",
       "1  Tue May 31 23:18:28 +0000 2016  Donald J. Trump 2016-06-01 11:58:19.858421   \n",
       "2  Tue May 31 23:17:33 +0000 2016  Donald J. Trump 2016-06-01 11:58:19.858424   \n",
       "3  Tue May 31 23:14:42 +0000 2016  Donald J. Trump 2016-06-01 11:58:19.858426   \n",
       "4  Tue May 31 22:51:56 +0000 2016  Donald J. Trump 2016-06-01 11:58:19.858428   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0           5854  So I raised/gave $5,600,000 for the veterans a...   \n",
       "1           4108  Congratulations to @seanhannity on his tremend...   \n",
       "2           5960  I am getting great credit for my press confere...   \n",
       "3           5870  Katie Couric, the third rate reporter, who has...   \n",
       "4           2151  I will be interviewed on @seanhannity tonight ...   \n",
       "\n",
       "             tweet_id  Polarity  Subjectivity  \n",
       "0  737996614573260800 -0.437500      0.708333  \n",
       "1  737785345459113985  0.333333      1.000000  \n",
       "2  737785114239864832  0.400000      0.425000  \n",
       "3  737784398515441664  0.107143      0.214286  \n",
       "4  737778668785766404  0.500000      0.500000  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. BONUS BONUS Apply PCA to your text features\n",
    "Is this effective? (ie: we could talk about LDA here a little bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing\n",
    "\n",
    "- What where the most impactful changes that helped your models?\n",
    "- What do you think would happen if we had more Trump Tweets than Sanders?\n",
    "- What other projects might you think to apply these problems against?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "widgets": {
   "state": {},
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
